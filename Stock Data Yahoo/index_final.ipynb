{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b47a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "from yahooquery import Ticker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93d9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea1302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.datetime(2024, 1, 1)\n",
    "end = dt.datetime(2025, 4, 13) #dt.datetime.now()\n",
    "\n",
    "# Diccionario con nombres de índices y sus símbolos de Yahoo Finance\n",
    "us_indices = {\n",
    "    'S&P 500': '^GSPC',\n",
    "    'Nasdaq': '^IXIC',\n",
    "    'Dow Jones': '^DJI',\n",
    "    'Russell 2000': '^RUT'\n",
    "}\n",
    "\n",
    "europe_indices = {\n",
    "    'FTSE 100': '^FTSE',\n",
    "    'DAX': '^GDAXI',\n",
    "    'CAC 40': '^FCHI',\n",
    "    'Euro Stoxx 50': '^STOXX50E',\n",
    "    'Euronext 100': '^N100'\n",
    "}\n",
    "\n",
    "latam_indices = {\n",
    "    'Bovespa': '^BVSP',\n",
    "    # 'IPSA (Chile)': '^IPSA',\n",
    "    'COLCAP (Colombia)': '^COLCAP',\n",
    "    # 'S&P/BVL General (Peru)': '^SPBLPGPT',\n",
    "    'MSCI Peru ETF': 'EPU'\n",
    "}\n",
    "\n",
    "asia_indices = {\n",
    "    'Nikkei 225 (Japan)': '^N225',\n",
    "    'Hang Seng (Hong Kong)': '^HSI',\n",
    "    'Shanghai Composite (China)': '000001.SS',\n",
    "    'Kospi (South Korea)': '^KS11'\n",
    "}\n",
    "\n",
    "# Función para descargar y normalizar datos\n",
    "# def get_normalized_data(indices, start, end):\n",
    "#     dataframes = []\n",
    "#     for name, ticker in indices.items():\n",
    "#         df = yf.download(ticker, start=start, end=end)[['Close']]\n",
    "#         time.sleep(5)\n",
    "#         df.rename(columns={'Close': name}, inplace=True)\n",
    "#         df = df.dropna(subset=[name])\n",
    "#         if not df.empty:\n",
    "#             df[name] = df[name] / df[name].iloc[0] * 100  # Normalizar a base 100\n",
    "#             dataframes.append(df)\n",
    "#     return dataframes\n",
    "\n",
    "def get_normalized_data(indices, start, end):\n",
    "    tickers = list(indices.values())\n",
    "    tq = Ticker(tickers)\n",
    "    data = tq.history(start=start.strftime('%Y-%m-%d'), end=end.strftime('%Y-%m-%d'))\n",
    "\n",
    "    if isinstance(data.index, pd.MultiIndex):\n",
    "        data = data.reset_index()\n",
    "\n",
    "    dataframes = []\n",
    "    for name, ticker in indices.items():\n",
    "        df = data[data['symbol'] == ticker][['date', 'close']]\n",
    "        df.set_index('date', inplace=True)\n",
    "        df.rename(columns={'close': name}, inplace=True)\n",
    "        df = df.dropna()\n",
    "        if not df.empty:\n",
    "            df[name] = df[name] / df[name].iloc[0] * 100  # Normalizar a base 100\n",
    "            dataframes.append(df)\n",
    "    return dataframes\n",
    "\n",
    "# Descargar y procesar datos para cada región\n",
    "us_dataframes = get_normalized_data(us_indices, start, end)\n",
    "europe_dataframes = get_normalized_data(europe_indices, start, end)\n",
    "latam_dataframes = get_normalized_data(latam_indices, start, end)\n",
    "asia_dataframes = get_normalized_data(asia_indices, start, end)\n",
    "\n",
    "# Función para combinar DataFrames\n",
    "def merge_dataframes(dataframes):\n",
    "    if dataframes:\n",
    "        merged_df = dataframes[0]\n",
    "        for df in dataframes[1:]:\n",
    "            merged_df = pd.merge(merged_df, df, left_index=True, right_index=True, how='outer')\n",
    "        return merged_df.fillna(method='ffill').fillna(method='bfill')\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Combinar DataFrames de cada región\n",
    "us_merged = merge_dataframes(us_dataframes)\n",
    "europe_merged = merge_dataframes(europe_dataframes)\n",
    "latam_merged = merge_dataframes(latam_dataframes)\n",
    "asia_merged = merge_dataframes(asia_dataframes)\n",
    "\n",
    "# Función para graficar los índices de una región\n",
    "def plot_indices(dataframe, title):\n",
    "    fig = go.Figure()\n",
    "    for column in dataframe.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=dataframe.index,\n",
    "            y=dataframe[column],\n",
    "            mode='lines',\n",
    "            name=column\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Fecha',\n",
    "        yaxis_title='Índice (Base 100)',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Mostrar gráficos para cada región\n",
    "plot_indices(us_merged, 'Índices de Estados Unidos (Base 100)')\n",
    "plot_indices(europe_merged, 'Índices de Europa (Base 100)')\n",
    "# plot_indices(latam_merged, 'Índices de América Latina (Base 100)')\n",
    "plot_indices(asia_merged, 'Índices de Asia (Base 100)')\n",
    "\n",
    "\n",
    "asia = asia_merged\n",
    "europe = europe_merged\n",
    "us = us_merged\n",
    "\n",
    "asia.index.name = None\n",
    "europe.index.name = None\n",
    "us.index.name = None\n",
    "\n",
    "asia_eu = asia.merge(europe, left_index=True, right_index=True, how='inner')\n",
    "asia_eu_us_index = asia_eu.merge(us, left_index=True, right_index=True, how='inner')\n",
    "asia_eu_us_index.columns.name = 'time' \n",
    "\n",
    "asia_eu_us_index.to_excel(\"../Stock Data Yahoo/data/asia_eu_us_index.xlsx\",sheet_name=\"Indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d39365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b64cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalizar índices para eliminar componentes de tiempo\n",
    "# asia_merged.index = asia_merged.index.normalize()\n",
    "# europe_merged.index = europe_merged.index.normalize()\n",
    "# us_merged.index = us_merged.index.normalize()\n",
    "\n",
    "asia_merged.index = pd.to_datetime(asia_merged.index).normalize()\n",
    "europe_merged.index = pd.to_datetime(europe_merged.index).normalize()\n",
    "us_merged.index = pd.to_datetime(us_merged.index).normalize()\n",
    "\n",
    "# Asegurarse de que los índices no tengan nombres\n",
    "asia_merged.index.name = None\n",
    "europe_merged.index.name = None\n",
    "us_merged.index.name = None\n",
    "\n",
    "# Realizar el merge secuencial\n",
    "asia_eu = asia_merged.merge(europe_merged, left_index=True, right_index=True, how='inner')\n",
    "asia_eu_us = asia_eu.merge(us_merged, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Restablecer el índice y renombrarlo como 'time'\n",
    "asia_eu_us.reset_index(inplace=True)\n",
    "asia_eu_us.set_index(\"index\", inplace=True)\n",
    "asia_eu_us.index.name = \"time\"\n",
    "\n",
    "# Exportar a una nueva hoja de un archivo de Excel existente\n",
    "output_file = \"merged_data.xlsx\"  # Nombre del archivo de salida\n",
    "sheet_name = \"Asia_EU_US_Merged\"  # Nombre de la nueva hoja\n",
    "\n",
    "# # Cargar el archivo existente y agregar una nueva hoja\n",
    "# with pd.ExcelWriter(output_file, engine='openpyxl', mode='a') as writer:\n",
    "#     asia_eu_us.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "# print(\"Datos exportados exitosamente a la hoja:\", sheet_name)\n",
    "asia_eu_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "asia = asia_merged\n",
    "europe = europe_merged\n",
    "us = us_merged\n",
    "\n",
    "asia.index.name = None\n",
    "europe.index.name = None\n",
    "us.index.name = None\n",
    "\n",
    "asia_eu = asia.merge(europe, left_index=True, right_index=True, how='inner')\n",
    "asia_eu_us_index = asia_eu.merge(us, left_index=True, right_index=True, how='inner')\n",
    "asia_eu_us_index.columns.name = 'time' \n",
    "\n",
    "asia_eu_us_index.to_excel(\"../Stock Data Yahoo/data/asia_eu_us_index.xlsx\",sheet_name=\"Indices\")\n",
    "\n",
    "# output_file = 'C:/Users/HP SUPPORT/Documents/GitHub/indicators/data/macro_dataset.xlsx'\n",
    "# # output_file = '../Documents/GitHub/indicators/data/macro_dataset.xlsx'\n",
    "# sheet_name = \"Indices\"\n",
    "# asia_eu_us_index\n",
    "\n",
    "# with pd.ExcelWriter(output_file, engine='openpyxl', mode='a') as writer:\n",
    "#     asia_eu_us_index.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "asia_eu_us_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6399a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asia.index.equals(europe.index))  # Debe ser True\n",
    "print(asia.index.equals(us.index))     # Debe ser True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b51b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410d25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eff133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b251c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Fechas de inicio y fin\n",
    "start = dt.datetime(2024, 1, 1)\n",
    "end = dt.datetime.now()\n",
    "\n",
    "# Diccionario con nombres de índices y sus símbolos de Yahoo Finance\n",
    "# latam_indices = {\n",
    "#     'Bovespa': '^BVSP',\n",
    "#     'IPC México': '^MXX',\n",
    "#     'Merval': '^MERV',\n",
    "#     'S&P/BVL General': '^SPBLPGPT',\n",
    "#     'MSCI Peru ETF': 'EPU'\n",
    "# }\n",
    "latam_indices = {\n",
    "    'Bovespa': '^BVSP',  # Brasil\n",
    "    'IPC México': '^MXX', #Mexico\n",
    "    'IPSA (Chile)': '^IPSA',  # Chile\n",
    "    'COLCAP (Colombia)': '^COLCAP',  # Colombia\n",
    "    'S&P/BVL General (Peru)': '^SPBLPGPT',  # Perú\n",
    "    'MSCI Peru ETF': 'EPU'  # ETF de Perú como representación del mercado\n",
    "}\n",
    "\n",
    "\n",
    "# Descargar y preparar datos de América Latina\n",
    "latam_dataframes = []\n",
    "for name, ticker in latam_indices.items():\n",
    "    df = yf.download(ticker, start=start, end=end)[['Close']]\n",
    "    df.rename(columns={'Close': name}, inplace=True)\n",
    "    \n",
    "    # Eliminar NaN al inicio\n",
    "    df = df.dropna(subset=[name])\n",
    "    \n",
    "    # Verificar si el DataFrame no está vacío antes de la normalización\n",
    "    if not df.empty:\n",
    "        df[name] = df[name] / df[name].iloc[0] * 100  # Normalizar a base 100\n",
    "        latam_dataframes.append(df)\n",
    "\n",
    "# Verificar que la lista de DataFrames no esté vacía antes del merge\n",
    "if latam_dataframes:\n",
    "    latam_merged = latam_dataframes[0]\n",
    "    for df in latam_dataframes[1:]:\n",
    "        latam_merged = pd.merge(latam_merged, df, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "\n",
    "    latam_merged = latam_merged.dropna()\n",
    "\n",
    "\n",
    "    # Crear gráfico para América Latina\n",
    "    fig = go.Figure()\n",
    "    for column in latam_merged.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=latam_merged.index,\n",
    "            y=latam_merged[column],\n",
    "            mode='lines',\n",
    "            name=column\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        title='Índices de América Latina (Base 100)',\n",
    "        xaxis_title='Fecha',\n",
    "        yaxis_title='Índice (Base 100)',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No hay datos válidos para los índices de América Latina.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a81200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2b5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Función para obtener los datos de un índice específico\n",
    "def get_investing_data(index_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    # Realizamos la solicitud GET al sitio web\n",
    "    response = requests.get(index_url, headers=headers)\n",
    "    \n",
    "    # Si la solicitud fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Encontramos la tabla de datos históricos (dependiendo de la estructura del HTML)\n",
    "        table = soup.find('table', {'class': 'genTbl closedTbl historicalTbl'})\n",
    "        \n",
    "        # Extraemos las filas de la tabla (cada fila es un día de datos)\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        # Creamos listas para almacenar los datos\n",
    "        dates = []\n",
    "        opens = []\n",
    "        highs = []\n",
    "        lows = []\n",
    "        closes = []\n",
    "        volumes = []\n",
    "        \n",
    "        # Iteramos sobre cada fila de datos\n",
    "        for row in rows[1:]:  # Saltamos la primera fila que es el encabezado\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:  # Si la fila tiene datos\n",
    "                dates.append(cols[0].text.strip())\n",
    "                opens.append(cols[1].text.strip())\n",
    "                highs.append(cols[2].text.strip())\n",
    "                lows.append(cols[3].text.strip())\n",
    "                closes.append(cols[4].text.strip())\n",
    "                volumes.append(cols[5].text.strip())\n",
    "        \n",
    "        # Convertimos las listas en un DataFrame de pandas\n",
    "        data = {\n",
    "            'Date': dates,\n",
    "            'Open': opens,\n",
    "            'High': highs,\n",
    "            'Low': lows,\n",
    "            'Close': closes,\n",
    "            'Volume': volumes\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Convertir las fechas al formato correcto (puedes ajustarlo según la región)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%b %d, %Y')\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"Error al obtener los datos\")\n",
    "        return None\n",
    "\n",
    "# URL del índice S&P Merval (puedes cambiar la URL para otros índices)\n",
    "url = 'https://www.investing.com/indices/sp-bvlmerval-historical-data'\n",
    "\n",
    "# Obtener los datos\n",
    "data = get_investing_data(url)\n",
    "\n",
    "# Mostrar los primeros registros\n",
    "if data is not None:\n",
    "    print(data.head())\n",
    "\n",
    "    # Guardar los datos en un archivo CSV\n",
    "    data.to_csv('sp_merval_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7977e",
   "metadata": {},
   "source": [
    "### LATAM Y CARIBE\n",
    "\n",
    "IPSA CHILE: https://es.investing.com/indices/ipsa-historical-data\n",
    "\n",
    "S&P LIMA GENERAL: https://es.investing.com/indices/lima-stock-exchange-general\n",
    "\n",
    "COLCAP: https://es.investing.com/indices/colcap\n",
    "\n",
    "S&P/BMV IPC (MXX): https://es.investing.com/indices/ipc\n",
    "\n",
    "S&P MERVAL: https://es.investing.com/indices/merv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd946f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a43d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango de fechas: 17.03.2025 - 18.04.2025\n",
      "       Fecha    Último   Apertura     Máximo     Mínimo Volumen  % Var\n",
      "0 2025-04-15  29635.17  29.725,68  29.971,63  29.618,31          -0.30\n",
      "1 2025-04-14  29725.68  29.450,70  29.828,94  29.446,71           0.91\n",
      "2 2025-04-13  29458.58  29.014,29  29.495,22  29.014,29           1.53\n",
      "3 2025-04-10  29013.90  28.485,83  29.137,22  28.485,83           1.84\n",
      "4 2025-04-09  28489.65  28.684,31  28.765,84  28.258,39          -0.68\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configura el navegador\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # si no quieres que se abra la ventana\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# URL del índice S&P Lima General\n",
    "url = \"https://es.investing.com/indices/lima-stock-exchange-general-historical-data\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # espera para que cargue el contenido dinámico\n",
    "\n",
    "# Aceptar cookies si aparece\n",
    "try:\n",
    "    cookie_btn = driver.find_element(By.XPATH, '//button[contains(text(), \"Aceptar\")]')\n",
    "    cookie_btn.click()\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Obtener fecha del rango visible\n",
    "fecha_rango = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[2]/div[2]/div[2]/div[1]/div[2]/div[2]/div[2]/div[2]/div').text\n",
    "print(\"Rango de fechas:\", fecha_rango)\n",
    "\n",
    "# Obtener la tabla\n",
    "tabla = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[2]/div[2]/div[2]/div[1]/div[2]/div[3]/table/tbody')\n",
    "filas = tabla.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# Parsear datos\n",
    "datos = []\n",
    "for fila in filas:\n",
    "    columnas = fila.find_elements(By.TAG_NAME, 'td')\n",
    "    datos.append([col.text for col in columnas])\n",
    "\n",
    "# Convertir a DataFrame\n",
    "columnas = ['Fecha', 'Último', 'Apertura', 'Máximo', 'Mínimo', 'Volumen', '% Var']\n",
    "df = pd.DataFrame(datos, columns=columnas)\n",
    "\n",
    "# Convertir columnas numéricas\n",
    "df['Último'] = df['Último'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False).astype(float)\n",
    "df['% Var'] = df['% Var'].str.replace('%', '').str.replace(',', '.', regex=False).astype(float)\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'], dayfirst=True)\n",
    "\n",
    "# Mostrar\n",
    "print(df.head())\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# FECHA INICIO: //*[@id=\"__next\"]/div[2]/div[2]/div[2]/div[1]/div[2]/div[2]/div[2]/div[3]/div[1]/div[1]/input\n",
    "# FECHA FIN: //*[@id=\"__next\"]/div[2]/div[2]/div[2]/div[1]/div[2]/div[2]/div[2]/div[3]/div[1]/div[2]/input\n",
    "# ACEPTAR : //*[@id=\"__next\"]/div[2]/div[2]/div[2]/div[1]/div[2]/div[2]/div[2]/div[3]/div[2]/span[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14bc2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2f6ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Último</th>\n",
       "      <th>Apertura</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Volumen</th>\n",
       "      <th>% Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>29635.17</td>\n",
       "      <td>29.725,68</td>\n",
       "      <td>29.971,63</td>\n",
       "      <td>29.618,31</td>\n",
       "      <td></td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>29725.68</td>\n",
       "      <td>29.450,70</td>\n",
       "      <td>29.828,94</td>\n",
       "      <td>29.446,71</td>\n",
       "      <td></td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>29458.58</td>\n",
       "      <td>29.014,29</td>\n",
       "      <td>29.495,22</td>\n",
       "      <td>29.014,29</td>\n",
       "      <td></td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>29013.90</td>\n",
       "      <td>28.485,83</td>\n",
       "      <td>29.137,22</td>\n",
       "      <td>28.485,83</td>\n",
       "      <td></td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>28489.65</td>\n",
       "      <td>28.684,31</td>\n",
       "      <td>28.765,84</td>\n",
       "      <td>28.258,39</td>\n",
       "      <td></td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>28684.31</td>\n",
       "      <td>27.972,13</td>\n",
       "      <td>28.812,86</td>\n",
       "      <td>27.972,13</td>\n",
       "      <td></td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>27974.37</td>\n",
       "      <td>27.841,22</td>\n",
       "      <td>28.378,02</td>\n",
       "      <td>27.841,22</td>\n",
       "      <td></td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-04-06</td>\n",
       "      <td>27840.85</td>\n",
       "      <td>28.158,26</td>\n",
       "      <td>28.214,46</td>\n",
       "      <td>26.745,57</td>\n",
       "      <td></td>\n",
       "      <td>-1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>28157.88</td>\n",
       "      <td>29.560,23</td>\n",
       "      <td>29.561,52</td>\n",
       "      <td>28.157,88</td>\n",
       "      <td></td>\n",
       "      <td>-4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>29564.26</td>\n",
       "      <td>30.216,47</td>\n",
       "      <td>30.216,47</td>\n",
       "      <td>29.556,68</td>\n",
       "      <td></td>\n",
       "      <td>-2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>30214.83</td>\n",
       "      <td>30.311,50</td>\n",
       "      <td>30.484,22</td>\n",
       "      <td>30.152,16</td>\n",
       "      <td></td>\n",
       "      <td>-0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>30324.70</td>\n",
       "      <td>30.103,64</td>\n",
       "      <td>30.423,90</td>\n",
       "      <td>30.078,34</td>\n",
       "      <td></td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>30089.72</td>\n",
       "      <td>30.118,07</td>\n",
       "      <td>30.205,49</td>\n",
       "      <td>29.787,72</td>\n",
       "      <td></td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-03-27</td>\n",
       "      <td>30127.13</td>\n",
       "      <td>30.222,49</td>\n",
       "      <td>30.422,43</td>\n",
       "      <td>30.018,92</td>\n",
       "      <td></td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-03-26</td>\n",
       "      <td>30249.91</td>\n",
       "      <td>30.269,34</td>\n",
       "      <td>30.457,98</td>\n",
       "      <td>30.174,22</td>\n",
       "      <td></td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>30257.70</td>\n",
       "      <td>30.692,54</td>\n",
       "      <td>30.693,16</td>\n",
       "      <td>30.170,05</td>\n",
       "      <td></td>\n",
       "      <td>-1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>30692.54</td>\n",
       "      <td>30.370,10</td>\n",
       "      <td>30.713,32</td>\n",
       "      <td>30.370,10</td>\n",
       "      <td></td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>30379.26</td>\n",
       "      <td>30.353,13</td>\n",
       "      <td>30.558,20</td>\n",
       "      <td>30.352,23</td>\n",
       "      <td></td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>30363.15</td>\n",
       "      <td>30.355,11</td>\n",
       "      <td>30.393,00</td>\n",
       "      <td>30.161,97</td>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>30363.49</td>\n",
       "      <td>30.017,84</td>\n",
       "      <td>30.363,49</td>\n",
       "      <td>29.998,61</td>\n",
       "      <td></td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>30032.77</td>\n",
       "      <td>29.927,79</td>\n",
       "      <td>30.127,01</td>\n",
       "      <td>29.687,52</td>\n",
       "      <td></td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>29928.61</td>\n",
       "      <td>29.882,15</td>\n",
       "      <td>30.048,62</td>\n",
       "      <td>29.794,97</td>\n",
       "      <td></td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fecha    Último   Apertura     Máximo     Mínimo Volumen  % Var\n",
       "0  2025-04-15  29635.17  29.725,68  29.971,63  29.618,31          -0.30\n",
       "1  2025-04-14  29725.68  29.450,70  29.828,94  29.446,71           0.91\n",
       "2  2025-04-13  29458.58  29.014,29  29.495,22  29.014,29           1.53\n",
       "3  2025-04-10  29013.90  28.485,83  29.137,22  28.485,83           1.84\n",
       "4  2025-04-09  28489.65  28.684,31  28.765,84  28.258,39          -0.68\n",
       "5  2025-04-08  28684.31  27.972,13  28.812,86  27.972,13           2.54\n",
       "6  2025-04-07  27974.37  27.841,22  28.378,02  27.841,22           0.48\n",
       "7  2025-04-06  27840.85  28.158,26  28.214,46  26.745,57          -1.13\n",
       "8  2025-04-03  28157.88  29.560,23  29.561,52  28.157,88          -4.76\n",
       "9  2025-04-02  29564.26  30.216,47  30.216,47  29.556,68          -2.15\n",
       "10 2025-04-01  30214.83  30.311,50  30.484,22  30.152,16          -0.36\n",
       "11 2025-03-31  30324.70  30.103,64  30.423,90  30.078,34           0.78\n",
       "12 2025-03-30  30089.72  30.118,07  30.205,49  29.787,72          -0.12\n",
       "13 2025-03-27  30127.13  30.222,49  30.422,43  30.018,92          -0.41\n",
       "14 2025-03-26  30249.91  30.269,34  30.457,98  30.174,22          -0.03\n",
       "15 2025-03-25  30257.70  30.692,54  30.693,16  30.170,05          -1.42\n",
       "16 2025-03-24  30692.54  30.370,10  30.713,32  30.370,10           1.03\n",
       "17 2025-03-23  30379.26  30.353,13  30.558,20  30.352,23           0.05\n",
       "18 2025-03-20  30363.15  30.355,11  30.393,00  30.161,97           0.00\n",
       "19 2025-03-19  30363.49  30.017,84  30.363,49  29.998,61           1.10\n",
       "20 2025-03-18  30032.77  29.927,79  30.127,01  29.687,52           0.35\n",
       "21 2025-03-17  29928.61  29.882,15  30.048,62  29.794,97           0.16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b63a5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b45980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a48ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11400a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694d27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1d6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40e326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
